import dotenv

dotenv.load_dotenv()

from openai import OpenAI
import asyncio
import base64
import streamlit as st
from agents import (
    Agent,
    Runner,
    SQLiteSession,
    WebSearchTool,
    FileSearchTool,
    ImageGenerationTool,
)

client = OpenAI()

VECTOR_STORE_ID = "vs_68d24d053a8c81919f57c07b61b9d899"


# Agent
if "agent" not in st.session_state:
    st.session_state["agent"] = Agent(
        name="ChatGPT Clone",
        instructions="""
        You are a helpful assistant.
 
        You have access to the followig tools:
            - Web Search Tool: Use this when the user asks a questions that isn't in your training data. Use this tool when the users asks about current or future events, when you think you don't know the answer, try searching for it in the web first.
            - File Search Tool: Use this tool when the user asks a question about facts related to themselves. Or when they ask questions about specific files.
        """,
        tools=[
            WebSearchTool(),
            FileSearchTool(
                vector_store_ids=[VECTOR_STORE_ID],
                max_num_results=3,
            ),
            ImageGenerationTool(  # PermissionDeniedError `gpt-image-1`(verification)
                tool_config={
                    "type": "image_generation",
                    "quality": "low",
                    "output_format": "jpeg",
                    "moderation": "low",
                    "partial_images": 1,  # loading image
                }
            ),
        ],
    )

agent = st.session_state["agent"]


# Session Ï¥àÍ∏∞Ìôî
if "session" not in st.session_state:
    st.session_state["session"] = SQLiteSession(
        "chat-history",  # ession id
        "chat-gpt-clone-memory.db",  # .db path
    )

session = st.session_state["session"]


async def paint_history():
    messages = await session.get_items()

    for message in messages:

        if "role" in message:
            with st.chat_message(message["role"]):
                if message["role"] == "user":
                    content = message["content"]  # refer to memory sample
                    if isinstance(content, str):
                        st.write(content)
                    elif isinstance(content, list):
                        for part in content:
                            if "image_url" in part:
                                st.image(part["image_url"])

                elif message["type"] == "message":
                    st.write(message["content"][0]["text"].replace("$", "\\$"))

        if "type" in message:
            message_type = message["type"]
            if message_type == "web_search_call":
                with st.chat_message("ai"):
                    st.write("Searching Web...")
            elif message_type == "file_search_call":
                with st.chat_message("ai"):
                    st.write("üóÇÔ∏è Searched your files...")
            elif message_type == "image_generation_call":
                image = base64.b64decode(message["result"])
                with st.chat_message("ai"):
                    st.image(image)


# Draw UI
asyncio.run(paint_history())


def update_status(status_container, event):

    # just for web search tool
    status_messages = {
        "response.web_search_call.completed": ("‚úÖ Web search completed.", "complete"),
        "response.web_search_call.in_progress": (
            "üîç Starting web search...",
            "running",
        ),
        "response.web_search_call.searching": (
            "üîç Web search in progress...",
            "running",
        ),
        "response.file_search_call.completed": (
            "‚úÖ File search completed.",
            "complete",
        ),
        "response.file_search_call.in_progress": (
            "üóÇÔ∏è Starting file search...",
            "running",
        ),
        "response.file_search_call.searching": (
            "üóÇÔ∏è File search in progress...",
            "running",
        ),
        "response.image_generation_call.generating": (
            "üé® Drawing image...",
            "running",
        ),
        "response.image_generation_call.in_progress": (
            "üé® Drawing image...",
            "running",
        ),
        "response.completed": (" ", "complete"),
    }

    if event in status_messages:
        label, state = status_messages[event]
        status_container.update(label=label, state=state)


# Runner
async def run_agent(message):
    with st.chat_message("ai"):
        status_container = st.status("‚è≥", expanded=False)
        text_placeholder = st.empty()
        image_placeholder = st.empty()
        response = ""

        stream = Runner.run_streamed(agent, message, session=session)

        async for event in stream.stream_events():
            if event.type == "raw_response_event":

                update_status(status_container, event.data.type)

                if event.data.type == "response.output_text.delta":
                    response += event.data.delta
                    text_placeholder.write(response.replace("$", "\\$"))

                elif event.data.type == "response.image_generation_call.partial_image":
                    image = base64.b64decode(event.data.partial_image_b64)
                    image_placeholder.image(image)

                elif event.data.type == "response.completed":
                    image_placeholder.empty()
                    text_placeholder.empty()


### UI ###

prompt = st.chat_input(
    "Write a message for your assistant",
    accept_file=True,
    file_type=["txt", "jpg", "jpeg", "png"],
)

if prompt:
    for file in prompt.files:
        if file.type.startswith("text/"):
            with st.chat_message("ai"):

                with st.status("‚è≥ Uploading file...") as status:
                    uploaded_file = client.files.create(
                        file=(
                            file.name,
                            file.getvalue(),
                        ),  # file: UploadedFile -> streamlit
                        purpose="user_data",
                    )

                    status.update(label="‚è≥ Attaching file...")
                    # file to vector store
                    client.vector_stores.files.create(
                        vector_store_id=VECTOR_STORE_ID,
                        file_id=uploaded_file.id,
                    )
                    status.update(label="‚úÖ File uploaded", state="complete")

        if file.type.startswith("image/"):
            with st.status("‚è≥ Uploading images...") as status:
                file_bytes = file.getvalue()  # get bytes
                base64_data = base64.b64encode(file_bytes).decode("utf-8")
                data_uri = f"data:{file.type};base64,{base64_data}"  # for chatgpt
                asyncio.run(
                    session.add_items(
                        [
                            {
                                "role": "user",
                                "content": [
                                    {
                                        "type": "input_image",
                                        "detail": "auto",
                                        "image_url": data_uri,
                                    }
                                ],
                            }
                        ]
                    )
                )
                status.update(label="‚úÖ Image uploaded", state="complete")
            with st.chat_message("human"):
                st.image(data_uri)

    if prompt.text:
        with st.chat_message("human"):
            st.write(prompt.text)
        asyncio.run(run_agent(prompt.text))


with st.sidebar:

    reset = st.button("Reset Memory")
    if reset:
        asyncio.run(session.clear_session())

    st.write(asyncio.run(session.get_items()))
