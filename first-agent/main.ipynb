{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# print(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-C8LFkavpsREYmGtuLgMky6N2yjJ2O', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Today is August 25, 2025.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1756104356, model='gpt-5-nano-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=275, prompt_tokens=10, total_tokens=285, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=256, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What's today's date?\"}],\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI()\n",
    "\n",
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ai():\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    # memory에 추가\n",
    "    message = response.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": message})\n",
    "    print(f\"AI: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I have a dog. Answer briefly.\n",
      "AI: Nice! What would you like help with—training, health, diet, or behavior? I can give quick, practical tips.\n",
      "User: What kind of animal do I have?\n",
      "AI: A dog. Want tips on training, health, or care?\n",
      "User: \n",
      "AI: If you’d like, tell me what you want help with—training, health, feeding, or behavior. Any details about breed, age, or goals will help me tailor tips.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    message = input(\"Input for LLM\")\n",
    "\n",
    "    if message == \"quit\" or message == \"q\":\n",
    "        break\n",
    "    else:\n",
    "        messages.append({\"role\": \"user\", \"content\": message})\n",
    "        print(f\"User: {message}\")\n",
    "        call_ai()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool Schema\n",
    "TOOLS = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"A function to get the weather of a city\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"city\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The name of the city to get the weather of.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"city\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: My name is JM. Answer briefly.\n",
      "ChatCompletion(id='chatcmpl-C8diru9CG43BmnsGr8nMNfyh1UrMG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Nice to meet you, JM. How can I help today?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1756175353, model='gpt-5-nano-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=278, prompt_tokens=148, total_tokens=426, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=256, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "AI: Nice to meet you, JM. How can I help today?\n",
      "User: Weather in Jeju\n",
      "ChatCompletion(id='chatcmpl-C8dj6rnSbrdzmnwuW95FYyym3sYhs', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='call_kBmPM97Q6SRqwNMekqcXgOs7', function=Function(arguments='{\"city\":\"Jeju\"}', name='get_weather'), type='function')]))], created=1756175368, model='gpt-5-nano-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=216, prompt_tokens=175, total_tokens=391, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=192, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "AI: None\n"
     ]
    }
   ],
   "source": [
    "def call_ai():\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        messages=messages,\n",
    "        tools=TOOLS,  # Adding Tools\n",
    "    )\n",
    "\n",
    "    print(response)\n",
    "\n",
    "    message = response.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": message})\n",
    "    print(f\"AI: {message}\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    message = input(\"Input for LLM\")\n",
    "\n",
    "    if message == \"quit\" or message == \"q\":\n",
    "        break\n",
    "    else:\n",
    "        messages.append({\"role\": \"user\", \"content\": message})\n",
    "        print(f\"User: {message}\")\n",
    "        call_ai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI: None ??\n",
    "ChatCompletion(\n",
    "    id=\"chatcmpl-C8dj6rnSbrdzmnwuW95FYyym3sYhs\",\n",
    "    choices=[\n",
    "        Choice(\n",
    "            finish_reason=\"tool_calls\",\n",
    "            index=0,\n",
    "            logprobs=None,\n",
    "            message=ChatCompletionMessage(\n",
    "                content=None,  # None\n",
    "                refusal=None,\n",
    "                role=\"assistant\",\n",
    "                annotations=[],\n",
    "                audio=None,\n",
    "                function_call=None,\n",
    "                tool_calls=[  # Tool Calls\n",
    "                    ChatCompletionMessageFunctionToolCall(\n",
    "                        id=\"call_kBmPM97Q6SRqwNMekqcXgOs7\",\n",
    "                        function=Function(\n",
    "                            arguments='{\"city\":\"Jeju\"}', name=\"get_weather\"\n",
    "                        ),\n",
    "                        type=\"function\",\n",
    "                    )\n",
    "                ],\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    created=1756175368,\n",
    "    model=\"gpt-5-nano-2025-08-07\",\n",
    "    object=\"chat.completion\",\n",
    "    ...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(city: str):\n",
    "    return \"00 degrees celcius.\"\n",
    "\n",
    "\n",
    "FUNCTION_MAP = {\"get_weather\": get_weather}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.chat import ChatCompletionMessage\n",
    "import json\n",
    "\n",
    "\n",
    "def process_ai_response(message: ChatCompletionMessage):\n",
    "    \"\"\"\n",
    "    message from ai.\n",
    "    run if the tool_call in messages.\n",
    "    add messages to memory and run tools.\n",
    "    and call_ai() with new messages (+ tool_request, tool_result)\n",
    "    \"\"\"\n",
    "\n",
    "    if message.tool_calls:\n",
    "\n",
    "        # to memory(request)\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": message.content or \"\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": tool_call.id,\n",
    "                        \"type\": \"function\",\n",
    "                        \"function\": {\n",
    "                            \"name\": tool_call.function.name,\n",
    "                            \"arguments\": tool_call.function.arguments,\n",
    "                        },\n",
    "                    }\n",
    "                    for tool_call in message.tool_calls\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # get name, arg from every tool_calls (ai-request)\n",
    "        for tool_call in message.tool_calls:\n",
    "\n",
    "            function_name = tool_call.function.name\n",
    "            arguments = tool_call.function.arguments\n",
    "\n",
    "            print(f\">> Calling function: {function_name} with {arguments}\")\n",
    "\n",
    "            try:\n",
    "                arguments = json.loads(arguments)  # string -> python obj\n",
    "            except json.JSONDecodeError:\n",
    "                arguments = {}\n",
    "\n",
    "            # Get func\n",
    "            function_to_run = FUNCTION_MAP.get(function_name)\n",
    "\n",
    "            # Run func\n",
    "            result = function_to_run(**arguments)\n",
    "            print(\n",
    "                f\">> Ran {function_name} with args {arguments} for a result of {result}\"\n",
    "            )\n",
    "\n",
    "            # to memory(result)\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": result,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        call_ai()\n",
    "\n",
    "    else:\n",
    "        messages.append({\"role\": \"assistant\", \"content\": message.content})\n",
    "        print(f\"AI: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: My name is JM. Answer briefly.\n",
      "AI: Nice to meet you, JM. How can I help?\n",
      "User: What is my name?\n",
      "AI: Your name is JM.\n",
      "User: What's the weather in Jeju?\n",
      ">> Calling function: get_weather with {\"city\":\"Jeju\"}\n",
      ">> Ran get_weather with args {'city': 'Jeju'} for a result of 00 degrees celcius.\n",
      "AI: Currently 0°C in Jeju. Want a forecast or more details?\n"
     ]
    }
   ],
   "source": [
    "def call_ai():\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        messages=messages,\n",
    "        tools=TOOLS,  # Adding Tools\n",
    "    )\n",
    "\n",
    "    process_ai_response(response.choices[0].message)\n",
    "\n",
    "\n",
    "while True:\n",
    "    message = input(\"Input for LLM\")  # 1. User send message\n",
    "\n",
    "    if message == \"quit\" or message == \"q\":\n",
    "        break\n",
    "    else:\n",
    "        messages.append(\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        )  # 2. Add message to memory\n",
    "        print(f\"User: {message}\")\n",
    "        call_ai()  # 3. Call AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'My name is JM. Answer briefly.'},\n",
       " {'role': 'assistant', 'content': 'Nice to meet you, JM. How can I help?'},\n",
       " {'role': 'user', 'content': 'What is my name?'},\n",
       " {'role': 'assistant', 'content': 'Your name is JM.'},\n",
       " {'role': 'user', 'content': \"What's the weather in Jeju?\"},\n",
       " {'role': 'assistant',\n",
       "  'content': '',\n",
       "  'tool_calls': [{'id': 'call_pxXpoRnBH5lLAYArSPY86b6V',\n",
       "    'type': 'function',\n",
       "    'function': {'name': 'get_weather', 'arguments': '{\"city\":\"Jeju\"}'}}]},\n",
       " {'role': 'tool',\n",
       "  'tool_call_id': 'call_pxXpoRnBH5lLAYArSPY86b6V',\n",
       "  'name': 'get_weather',\n",
       "  'content': '00 degrees celcius.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Currently 0°C in Jeju. Want a forecast or more details?'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages  # 2.6 Tool Results - 6:50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jeju'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# String\n",
    "a = '{\"city\": \"Jeju\"}'\n",
    "a[city]  # NameError: name 'city' is not defined\n",
    "\n",
    "# Python Object(Dictionary)\n",
    "b = json.loads(a)\n",
    "b[\"city\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_weather(**b)  # str -> city='Jeju'\n",
    "get_weather(city=\"Jeju\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
